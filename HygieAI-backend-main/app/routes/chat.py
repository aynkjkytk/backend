# app/routes/chat.py
from flask import Blueprint, request, jsonify
from app.utils.qwen_client import summarize_prediction
import numpy as np
import pandas as pd
import joblib
from pathlib import Path

chat_bp = Blueprint('chat', __name__, url_prefix='/api')

# ======= é¢„åŠ è½½æ¨¡å‹ï¼ˆæ¨¡å—çº§åˆ«ä¸€æ¬¡æ€§åŠ è½½ï¼‰=======
MODEL_DIR = Path("data/model")
MODELS = {
    "Bleeding":  MODEL_DIR / "ensemble-learning/ipn_bleeding_ensemble.pkl",
    "Infection": MODEL_DIR / "ensemble-learning/ipn_infection_ensemble.pkl",
    "Outcome":   MODEL_DIR / "ensemble-learning/ipn_blend_bundle.pkl"
}
loaded_models = {}
for name, path in MODELS.items():
    if path.exists():
        loaded_models[name] = joblib.load(path)
    else:
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {path}")

def feat_names(model):
    if isinstance(model, dict):
        return model["weighted_lgb"].named_steps["prep"].feature_names_in_
    else:
        return model.named_steps["prep"].feature_names_in_

def introduction_reply(data):
    """
    å›å¤æœºå™¨äººåŠŸèƒ½ä»‹ç»
    """
    return jsonify({
        "intent": "introduction",
        "message": (
            "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ HygieAIï¼Œæ˜¯ä¸€åæ™ºèƒ½èƒ°è…ºåŒ»ç”ŸåŠ©æ‰‹ã€‚"
            "æˆ‘å¯ä»¥ï¼š\n"
            "1ï¸âƒ£ å›ç­”ç›¸å…³çš„åŒ»å­¦é—®é¢˜\n"
            "2ï¸âƒ£ æ¥æ”¶ä¸´åºŠç‰¹å¾ï¼Œè°ƒç”¨æ¨¡å‹é¢„æµ‹è…¹è…”å‡ºè¡€/æ„ŸæŸ“ä¸æ‰‹æœ¯å¤±è´¥é£é™©\n"
            "æ¬¢è¿éšæ—¶å‘æˆ‘æé—®å“¦~æˆ‘ä¸€ç›´éƒ½åœ¨ğŸ‘Œ"
        )
    })

def other_reply(data):
    """
    å›å¤ä¸åŒ»å­¦æ— å…³å†…å®¹
    """
    return jsonify({
        "intent": "other",
        "message": "âš ï¸ å¾ˆæŠ±æ­‰ï¼Œå¯èƒ½æœ‰ç¥ç§˜åŠ›é‡é˜»æ­¢æˆ‘ç†è§£æ‚¨çš„é—®é¢˜ã€‚"
    })

def chat_reply(data):
    """
    é€šä¹‰åƒé—®é—®ç­”
    """
    question = data.get("question", "")
    from app.utils.qwen_client import ask_qwen
    answer = ask_qwen(question)

    return jsonify({
        "intent": "chat",
        "message": answer
    })

def prediction_reply(data: dict):
    """
    è¿”å›é¢„æµ‹ç±»è¯·æ±‚çš„å¼•å¯¼è¯­ï¼Œæç¤ºç”¨æˆ·è¾“å…¥ç»“æ„åŒ–ä¿¡æ¯ã€‚
    """
    return jsonify({
        "intent": "prediction",
        "message": "ğŸ§  æˆ‘å¯ä»¥å¸®åŠ©æ‚¨é¢„æµ‹ç›¸å…³é£é™©...è¯·åœ¨è¡¨å•ä¸­å¡«å†™ç›¸å…³ä¿¡æ¯",
        "require_form": True
    })

@chat_bp.route('/intent', methods=['POST'])
def intent_router():
    """
    ä¸»æ¥å£ï¼šè¯†åˆ« intentï¼Œå¹¶åˆ†å‘ç»™å¯¹åº”æ¥å£å¤„ç†
    """
    data = request.get_json(silent=True) or {}
    question = (data.get("question") or "").strip()

    if not question:
        return jsonify({"message": "â— è¯·æä¾›å­—æ®µ question"}), 400

    from app.utils.qwen_client import detect_intent

    intent = detect_intent(question)
    data["intent"] = intent   # å¯ä¼ é€’ä¸‹å»ç”¨
    print(intent)

    # åŠ¨æ€è·¯ç”±åˆ†å‘
    if intent == "introduction":
        return introduction_reply(data)
    elif intent == "prediction":
        return prediction_reply(data)
    elif intent == "chat":
        return chat_reply(data)
    else:
        return other_reply(data)

@chat_bp.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(silent=True) or {}

    icd_codes = data.get("icd_codes", [])   # e.g. ["D0001", "D0002", ...]
    features = data.get("features", {})     # ç»“æ„åŒ–ç‰¹å¾ï¼Œå¦‚ {"å¹´é¾„": 45, "ä½“é‡": 66, ...}

    if not isinstance(icd_codes, list) or not isinstance(features, dict):
        return jsonify({"error": "æ ¼å¼é”™è¯¯ï¼Œè¯·ä¼ å…¥ icd_codes åˆ—è¡¨ å’Œ features å­—å…¸"}), 400

    all_cols = sorted({c for m in loaded_models.values() for c in feat_names(m)})
    icd_cols = [c for c in all_cols if c.startswith("icd_")]
    other_cols = [c for c in all_cols if not c.startswith("icd_")]

    # æ„å»ºä¸€è¡Œè¾“å…¥æ•°æ®
    row = {}
    for col in other_cols:
        val = features.get(col, None)
        row[col] = np.nan if val is None else float(val)

    for ic in icd_cols:
        row[ic] = 1 if ic.split("icd_")[1] in icd_codes else 0

    df = pd.DataFrame([row], columns=all_cols)

    # é€æ¨¡å‹æ¨ç†
    result = {}
    for name, model in loaded_models.items():
        feats = feat_names(model)
        if name != "Outcome":
            prob = model.predict_proba(df[feats])[:, 1][0]
        else:
            alpha = model["alpha"]
            thresh = model.get("threshold", 0.5)
            lgbm = model["weighted_lgb"]
            voting = model["undersample_voting"]
            prob_l = lgbm.predict_proba(df[feats])[:, 1][0]
            prob_v = voting.predict_proba(df[feats])[:, 1][0]
            prob = alpha * prob_l + (1 - alpha) * prob_v
        result[name] = round(prob, 4)
    
    message = summarize_prediction(result)
    return jsonify({
        "result": result,
        "message": message
    })